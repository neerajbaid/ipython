{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI Lab 3: Spike Sorting with PCA\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Fall 2015 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Task 1: Two Neuron Spike Sorting](#task1)\n",
    "* [Task 2: Three Neuron Spike Sorting](#task2)\n",
    "* [Task 3: Determining Neurons](#task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first BMI lab, we saw that if we have (1) the spike timestamps from some neurons and (2) the corresponding joint angle of the subject, we can create a model to predict the joint angle of a subject from some more spike timestamps. These spike timestamps are gathered from electrodes, but the electrodes could be recording more than 1 neuron at the same time. To make predictions based on neuron firing rates, we need to be able to distinguish spikes that come from different neurons. \n",
    "\n",
    "Luckily for us, it is highly unlikely for two neurons next to each other to fire at precisely the same time, so in practice the \"average\" potential waveform looks like a sum of spike waveforms from different neurons. Additionally, each neuron has its own spike \"signature\" unique to that neuron. This is due to the physical characteristics of neurons, such as their shape and structure. It is impossible to know beforehand how many neurons an electrode measures or what each neuron's spike waveform looks like, so we must first separate the spikes from the different neurons near the electrode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "##<span style=\"color:blue\">Task 1: Two Neuron Spike Sorting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spike occurs when the potential passes a certain threshold in a neuron. In our data set, each recorded waveform contains `N=32` samples taken at a sampling frequency of 40kHz, which means the time difference between each consecutive sample is 800$\\mu$s. We can represent each vector exactly with any 32-dimensional basis, as long as the vectors making up the basis are linearly independent. However, we want to compute a minimal set of basis vectors that brings out the features of the data using Principal Component Analysis (PCA).\n",
    "\n",
    "For this lab, we will work with data from a single electrode which records the activity of up to 3 different neurons. We provide both training and test sets with two and three neurons. The two-neuron data set lets us visualize using a 2D scatter plot while the three-neuron data set requres a 3D scatter plots. The neurons have also been presorted using a professional software, so we can check our model against presorted data.\n",
    "\n",
    "Import the data sets and see the average waveform for each presorted neuron by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load data\n",
    "presorted = {k: v for k, v in scipy.io.loadmat('spike_waveforms').items() \\\n",
    "             if k in ('sig118a_wf', 'sig118b_wf', 'sig118c_wf')}\n",
    "presorted = [presorted['sig118a_wf'], presorted['sig118b_wf'], presorted['sig118c_wf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_training_set(data):\n",
    "    \"\"\" Separate data set into 2 sets. \n",
    "    1/6 of the dataset is training set and the rest is test set\n",
    "    Parameter:\n",
    "        data: waveform data (width = number of samples per spike)\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    idx_training = np.random.choice(n, n//6, replace=False)\n",
    "    training_set = data[idx_training]\n",
    "    test_set = [data[i] for i in range(n) if n not in idx_training]\n",
    "    return training_set, test_set\n",
    "\n",
    "# Create training and testing dataset\n",
    "two_neurons_training, two_neurons_test = _make_training_set(np.concatenate(presorted[1:]))\n",
    "three_neurons_training, three_neurons_test = _make_training_set(np.concatenate(presorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what the spikes look like. Below, we first plot 100 random spikes. Then, we plot the 3 distinct neuron's shape, taking the average over all of the samples gathered from that neuron based on the presorted data. The goal of this lab is to classify each of the line in the first plot to one of the neurons in the second plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 100 random spikes\n",
    "for waveforms in three_neurons_training[:100]:\n",
    "    plt.plot(waveforms)\n",
    "plt.xlim((0,31))\n",
    "plt.title('100 random spikes')\n",
    "\n",
    "# Plot the 3 spike shapes based on the presorted data\n",
    "plt.figure()\n",
    "for waveforms in presorted:\n",
    "    plt.plot(np.mean(waveforms, axis=0))\n",
    "plt.xlim((0,31))\n",
    "plt.title('Averaged presorted 3 neuron spikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent each spike in a lower dimensional space using PCA. In your implementation of PCA you will decide how to choose these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Using PCA, what will be the principal components if we use data from an electrode that measures 2 neurons?** Describe a special property of the first principal component.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Using PCA, what will be the principal components if we use data from an electrode that measures 3 neurons?** Describe a special property of the first two principal components.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html\">np.linalg.svd</a> in your PCA function. Read the documentation for this function to figure out how to choose the principal components used as the basis for the lower dimensional space.\n",
    "\n",
    "**<font color=\"red\">What does SVD return and how will you use those results?**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the functions below to implement PCA training and classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PCA_train(training_set, n_components):\n",
    "    \"\"\" Use np.linalg.svd to perform PCA\n",
    "    Parameters:\n",
    "        training_set: the data set to perform PCA on (MxN)\n",
    "        n_components: the dimensionality of the basis to return (i.e. number of neurons)\n",
    "    Returns: \n",
    "        The n_components principal components with highest significants and \n",
    "        the mean of each column of the original data\n",
    "    Hint1: Subtract the mean of the data first so the average of each column is 0. The axis \n",
    "        parameter of np.mean is helpful here.\n",
    "    Hint2: Find out a special property of the \"s\" returned by np.linalg.svd either by printing\n",
    "        it out or reading the documentation.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE #\n",
    "    mean =\n",
    "    basis_components = \n",
    "\n",
    "    \n",
    "    return basis_components, mean\n",
    "\n",
    "def PCA_classify(data, new_basis, mean):\n",
    "    \"\"\" Project the data set, adjusted by the mean, into the new basis vectors\n",
    "    Parameters:\n",
    "        data: data to project (MxN)\n",
    "        new_basis: new bases (KxN)\n",
    "        mean: mean of each timestamp from PCA (list of length N)\n",
    "    Returns: \n",
    "        Data projected onto new_basis (MxK)\n",
    "    Hint: Don't forget to adjust the data with the PCA training mean!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First call `PCA_train` on `two_neurons_training` and plot the 2 principal components. Note that since the dataset is randomized, you might get different plots every time you run the second code cell of this notebook (the `_make_training_set` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform PCA and plot the first 2 principal components.\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "two_new_basis, two_mean ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now classify `two_neurons_test` using that model and produce a scatter plot in the new basis. We will also try classifying the presorted data containing 2 neurons so we can see how the model behaves on the 2 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Project the test data two_neurons_test to the basis you found earlier\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "two_classified =\n",
    "\n",
    "\n",
    "plt.scatter(*two_classified.T)\n",
    "plt.title('two_neurons_test')\n",
    "\n",
    "# Project the presorted data and plot it\n",
    "plt.figure()\n",
    "presorted_two_classified = [PCA_classify(spikes, two_new_basis, two_mean) for spikes in presorted[1:]]\n",
    "colors = ['#0000ff', '#00ff00']\n",
    "for dat, color in zip(presorted_two_classified, colors):\n",
    "    plt.scatter(*dat.T, c=color)\n",
    "plt.title('Presorted data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first principal component separates the two neurons in the $x$-axis. Thus, technically we only need 1 principal component to separate the two neurons. This is because the algorithm maximizes the square of the dot product of each signal with the principal component, which results in a large positive dot product with 1 neuron and a large negative dot product with the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "##<span style=\"color:blue\">Task 2: Three Neuron Spike Sorting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `PCA_train` on `three_neurons_training` and plot the 3 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat training with three neuron data, producing 3 principal components\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "three_new_basis, three_mean ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same classification process as the 2 neuron data, but now with the 3 neuron data. Compare your model's behavoir with that of the presorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_3D(data, view_from_top=False):\n",
    "    \"\"\" Takes list of arrays (x, y, z) coordinate triples\n",
    "    One array of triples per color\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors = ['#0000ff', '#00ff00', '#ff0000']\n",
    "    for dat, color in zip(data, colors):\n",
    "        Axes3D.scatter(ax, *dat.T, c=color)\n",
    "    if view_from_top:\n",
    "        ax.view_init(elev=90.,azim=0)                # Move perspective to view from top\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "three_classified =\n",
    "\n",
    "\n",
    "plot_3D([three_classified], False)\n",
    "plt.title('three_neurons_test projected to 3 principal components')\n",
    "\n",
    "presorted_classified = [PCA_classify(spikes, three_new_basis, three_mean) for spikes in presorted]\n",
    "plot_3D(np.array(presorted_classified), False)\n",
    "plt.title('Presorted data projected to 3 principal components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">How many principal components do you actually need to cluster the 3 neurons?** Change the second argument to the `plot_3D` function calls above to True to view the plots \"from the top\" (i.e. looking down the positive z axis).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "##<span style=\"color:blue\">Task 3: Determining Neurons</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seperated the data into clusters, we can use k-means clustering to determine how many times each neuron fired. We can use this information to create a rough estimate for the average firing rate of each neuron over the time spanned by the given data.\n",
    "\n",
    "Scipy just happens to have a function to compute k-means given clustered data, which we have conveniently formatted formated above. First, read the documentation for the function scipy.cluster.vq.kmeans <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html#scipy.cluster.vq.kmeans\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Based on the documentation for scipy.cluster.vq.kmeans, how will we be able to adjust our approach for the 2-neuron and 3-neuron data sets?**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with how the function works, lets try to determine how many times each neuron fired in the 2-neuron data set. Start by determining the centroids of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(clustered_data, num_of_clusters):\n",
    "    \"\"\" Use scipy.cluster.vq.kmeans to determine centroids of clusters\n",
    "    Parameters:\n",
    "        clustered_data: the data projected onto the new basis\n",
    "        num_of_clusters: the expected number of clusters in the data\n",
    "    Returns: \n",
    "        The centroids of the clusters\n",
    "    Hint 1: make sure to first 'whiten' the data (refer to docs)\n",
    "    \"\"\"\n",
    "    whitened_data = scipy.cluster.vq.whiten(clustered_data)\n",
    "    return scipy.cluster.vq.kmeans(whitened_data, num_of_clusters)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call find_centroids on the projected 2-neuron data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine the centroids in the 2-neuron data\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "centroid_list =\n",
    "\n",
    "# Print the centroid locations\n",
    "centroid1 = centroid_list[0]\n",
    "centroid2 = centroid_list[1]\n",
    "\n",
    "print('The first centroid is at: ' + str(centroid1))\n",
    "print('The second centroid is at: ' + str(centroid2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note about the centroids we just found is that they have been normalized (by the \"whiten\" process), so they don't appear to match with the plot we made above. However, they should match the general location of the two clusters.\n",
    "\n",
    "Now that we have the location of the clusters, we can determine which neuron fired for each data point. We will do this by determing the centroid closer to the data point in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_neuron(data_point, centroid1, centroid2):\n",
    "    \"\"\" Determine which centroid is closest to the data point\n",
    "    Inputs:\n",
    "        data_point: 1x2 array containing x/y coordinates of data point\n",
    "        centroid1: 1x2 array containing x/y coordinates of centroid 1\n",
    "        centroid2: 1x2 array containing x/y coordinates of centroid 1\n",
    "    Returns: \n",
    "        The centroid closest to the data point\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply this to the two_classified data set and count the number of times each neuron fired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine how many times neuron1 and neuron2 fired in the two_classifed data\n",
    "# Hint: remember that we \"whitened\" the data to determine the centroids\n",
    "\n",
    "num_of_firings = np.zeros(2)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "    \n",
    "# Print the results\n",
    "print('Neuron 1 Fired ' + str(num_of_firings[0]) + ' times')\n",
    "print('Neuron 2 Fired ' + str(num_of_firings[1]) + ' times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined how many times each neuron fired over all of our data collections, we can use this to construct an \"average firing rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the average firing rate\n",
    "\n",
    "total_time = 32*800E-6*len(two_neurons_test)\n",
    "print('Average firing rate of Neuron 1: ' + str(num_of_firings[0]/total_time) + ' times per second')\n",
    "print('Average firing rate of Neuron 2: ' + str(num_of_firings[1]/total_time) + ' times per second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the first lab used neuron firing rate to help compute the angle of the arm. This lab demonstrated how we can go from the raw data collected from electrodes physically connected to a subject to data that is ready to be processed in the fashion of Lab 1.\n",
    "\n",
    "The point of the BMI labs was to demonstrate how we can collect, proceess, and use data to make assumptions about the original human (or animal) subject. This is just a starting point - there are limitless ways to use the end results to create systems that integrate directly with humans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
